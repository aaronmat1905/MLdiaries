{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF4WjC06OPbVTBdtzuSr3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronmat1905/MLdiaries/blob/main/Artificial%20Neural%20Networks/ArtificialNeuralNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0RhI9kUQZcIs"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assume that:**\n",
        "- **Polynomial Type**:\n",
        "$$\n",
        "y = 0.96x^2 + 7.35x + 7.07\n",
        "$$\n",
        "- **Noise Level**:\n",
        "$$\n",
        "ϵ \\sim N(0, 2.42)\n",
        "$$\n",
        "- **Architecture**: \\\n",
        "Input(1) → Hidden(32) → Hidden(72) → Output(1)\n",
        "- **Learning Rate (α)** = 0.005\n",
        "- **Architecture**: Narrow-To-Wide Architecture"
      ],
      "metadata": {
        "id": "jPQ0CZGeaNz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading**"
      ],
      "metadata": {
        "id": "E-mMBs4WDrlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in our dataset: <Synthetically Generated>\n",
        "# Loading in our dataset: <Synthetically Generated>\n",
        "datasetPath = \"ann_dataset.csv\"\n",
        "ann_data = pd.read_csv(datasetPath)\n",
        "ann_data.info()\n",
        "print(\"\\n+++++++++++++++++++++++++\\n\")\n",
        "ann_data.head(5)"
      ],
      "metadata": {
        "id": "hdpedx_xcGYM",
        "outputId": "8e8e4bc3-1ad7-423d-e761-1b2ba50ebc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   x       100000 non-null  float64\n",
            " 1   y       100000 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.5 MB\n",
            "\n",
            "+++++++++++++++++++++++++\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           x            y\n",
              "0 -55.601366  2547.648326\n",
              "1  74.146461  5803.114349\n",
              "2 -58.656169  2864.092846\n",
              "3  83.722182  7324.122723\n",
              "4  -2.317762    -1.245122"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d3af81b-de52-4c3a-91ed-f3eb76918ab5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-55.601366</td>\n",
              "      <td>2547.648326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>74.146461</td>\n",
              "      <td>5803.114349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-58.656169</td>\n",
              "      <td>2864.092846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83.722182</td>\n",
              "      <td>7324.122723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.317762</td>\n",
              "      <td>-1.245122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d3af81b-de52-4c3a-91ed-f3eb76918ab5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d3af81b-de52-4c3a-91ed-f3eb76918ab5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d3af81b-de52-4c3a-91ed-f3eb76918ab5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8fa32921-cd50-44be-a1f3-e239dae34654\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fa32921-cd50-44be-a1f3-e239dae34654')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8fa32921-cd50-44be-a1f3-e239dae34654 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ann_data",
              "summary": "{\n  \"name\": \"ann_data\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.65028013334275,\n        \"min\": -99.99975935929236,\n        \"max\": 99.99902373611826,\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          -75.83968803332172,\n          41.16539782811199,\n          10.830659449117915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2874.4460450064653,\n        \"min\": -15.039608966161218,\n        \"max\": 10301.60993226984,\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          4941.731489137534,\n          1924.995765800459,\n          199.72377837945643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Activation Functions**\n",
        "**ReLU**:\n",
        "\n",
        "*Rectified Linear Unit*\n",
        "$$\n",
        "f(x) = max(0, x)\n",
        "$$\n",
        "- The ReLU function returns the maximum between between it's input and zero.\n",
        "- Advantages:\n",
        "  - It helps mitigate the Vanishing gradient problem.\n",
        "  - Leads to efficient computation, since, It eliminates all negative outputs.\n",
        "  - Allows NNs to scale to many layers without a significant increase in computational burden.\n",
        "\n",
        "___\n",
        "**ReLU Derivative**\n",
        "The derivative of a function measures how much it changes it's slope:\n",
        "\n",
        "*Here, we have to measure it's slope/derivative of the function in each region*\n",
        "\n",
        "**Case Analysis:**\n",
        "- Case 1: 𝒳 > 0:\n",
        "  - In this region, f(𝒳) = 𝒳 ; **f'(𝒳) = 1**\n",
        "- Case 2: 𝒳 < 0:\n",
        "  - In this region, f(𝒳) = 0 ; **f'(𝒳) = 0**\n",
        "- Case 3: 𝒳 = 0:\n",
        "  - Left Hand Derivative: = 0\n",
        "  - Right Hand Derivative: = 1\n",
        "  - Therefore, the derivative at 𝒳 = 0 is undefined.\n"
      ],
      "metadata": {
        "id": "HkVC0RgAhSpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "  return max(0, z)\n",
        "\n",
        "def relu_derivative(z):\n",
        "  answer = relu(z)\n",
        "  if answer < 0:\n",
        "    return 0\n",
        "  elif answer > 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "eFBhdhPLhSQT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss Function**\n",
        "**MSE**:\n",
        "\n",
        "MSE, or Mean Squared error measures the average squared difference between the actual observed values and values predicted by a model.\n",
        "- Smaller MSE ⇒ Models predictions closer to the actual data.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{MSE}} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
        "$$"
      ],
      "metadata": {
        "id": "jFhgpkuDpjqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(y_true, y_pred):\n",
        "  # Assuming y_true and y_pred are numpy arrays\n",
        "  N = len(y_true)\n",
        "  return (1/N)*np.sum(y_true - y_pred)"
      ],
      "metadata": {
        "id": "mE9AOWxoprmV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Weight Initialization**\n",
        "> Weight initialization is the process of setting the starting values of the weights (parameters) in a neural network before the training begins.\n",
        "\n",
        "Since training relies on *gradient descent*, the initial weights heavily influence the:\n",
        "  - Convergence speed (How fast training progresses)\n",
        "  - Avoiding poor local minima\n",
        "  - Preventing vanishing or exploding gradients in deep network.\n",
        "\n",
        "**Why not start with all 0s?**\n",
        "\n",
        "If so, every neuron in a layer learns the same thing (*symmetry problem*). Gradient updates will be identical, so network won't learn effectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "OWSOsL1r7PIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Xavier (Glorot) Initialization**\n",
        "\n",
        "### ***The Core Idea***\n",
        "\n",
        "A neuron’s output is a weighted sum of its inputs:\n",
        "\n",
        "$$\n",
        "z_j^{(l)} = \\sum_{i=1}^{n_{in}} W_{ji}^{(l)} x_i^{(l-1)}\n",
        "$$\n",
        "\n",
        "Here:\n",
        "\n",
        "* $n_{in}$ = number of inputs (fan-in)\n",
        "* $n_{out}$ = number of outputs (fan-out)\n",
        "* $W_{ji}$ = weights\n",
        "* $x^{(l-1)}$ = activations from the previous layer\n",
        "\n",
        "For stable training, we want two things:\n",
        "\n",
        "1. The **variance of activations** remains consistent across layers (forward stability).\n",
        "2. The **variance of gradients** remains consistent across layers (backward stability).\n",
        "\n",
        "---\n",
        "\n",
        "### ***Forward Stability***\n",
        "\n",
        "The variance of the output $z_j^{(l)}$ depends on the variance of weights and inputs:\n",
        "\n",
        "$$\n",
        "Var[z_j^{(l)}] = n_{in} \\cdot Var[W] \\cdot Var[x^{(l-1)}]\n",
        "$$\n",
        "\n",
        "To avoid activations shrinking or exploding, we want:\n",
        "\n",
        "$$\n",
        "Var[z_j^{(l)}] \\approx Var[x^{(l-1)}]\n",
        "$$\n",
        "\n",
        "This gives:\n",
        "\n",
        "$$\n",
        "Var[W] = \\frac{1}{n_{in}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### ***Backward Stability***\n",
        "\n",
        "During backpropagation, gradients flow through weights as well. Their variance depends on $n_{out}$:\n",
        "\n",
        "$$\n",
        "Var\\left[\\frac{\\partial L}{\\partial x^{(l-1)}}\\right] = n_{out} \\cdot Var[W] \\cdot Var\\left[\\frac{\\partial L}{\\partial z^{(l)}}\\right]\n",
        "$$\n",
        "\n",
        "For stable gradients:\n",
        "\n",
        "$$\n",
        "Var[W] = \\frac{1}{n_{out}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### ***The Compromise***\n",
        "\n",
        "* Forward pass prefers: $Var[W] = \\frac{1}{n_{in}}$\n",
        "* Backward pass prefers: $Var[W] = \\frac{1}{n_{out}}$\n",
        "\n",
        "Xavier/Glorot initialization takes a **compromise** between the two:\n",
        "\n",
        "$$\n",
        "Var[W] = \\frac{2}{n_{in} + n_{out}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### ***Practical Formulations***\n",
        "\n",
        "From this variance, we can define two initialization schemes:\n",
        "\n",
        "* **Uniform Distribution**\n",
        "\n",
        "$$\n",
        "W \\sim U\\left(-\\sqrt{\\frac{6}{n_{in}+n_{out}}}, \\; \\sqrt{\\frac{6}{n_{in}+n_{out}}}\\right)\n",
        "$$\n",
        "\n",
        "* **Normal Distribution**\n",
        "\n",
        "$$\n",
        "W \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{in}+n_{out}}\\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "✅ **Summary:**\n",
        "Xavier Initialization is a weight initialization method that ensures both forward activations and backward gradients maintain a stable variance throughout the network, preventing vanishing or exploding signals. It achieves this by balancing between the input and output layer sizes, setting the weight variance to:\n",
        "\n",
        "$$\n",
        "Var[W] = \\frac{2}{n_{in} + n_{out}}\n",
        "$$"
      ],
      "metadata": {
        "id": "dgE1nSOg8o2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pseudocode for the Xavier-init method:\n",
        "```\n",
        "function Xavier_Init(n_in, n_out, distribution):\n",
        "    if distribution == \"uniform\":\n",
        "        limit = sqrt(6 / (n_in + n_out))\n",
        "        W = random_uniform(-limit, +limit, size=(n_out, n_in))\n",
        "    else if distribution == \"normal\":\n",
        "        sigma = sqrt(2 / (n_in + n_out))\n",
        "        W = random_normal(0, sigma, size=(n_out, n_in))\n",
        "    return W\n",
        "```"
      ],
      "metadata": {
        "id": "R7ywHRS-_pws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xavier_initialization(data, input_dim, hidden1, hidden2, output_dim):\n",
        "  seed = data[1][0]\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  # Input -> Hidden1\n",
        "  xavier_std1 = np.sqrt(2/(input_dim+hidden1))\n",
        "  w1 = np.random.normal(0, xavier_std1, (hidden1, input_dim)) # Initialize weights\n",
        "  b1 = np.zeroes((hidden1, 1)) # Initializing Biases\n",
        "\n",
        "  # Hidden1 -> Hidden2\n",
        "  xavier_std2 = np.sqrt(2/(hidden1+hidden2))\n",
        "  w2 = np.random.normal(0, xavier_std2, (hidden2, hidden1))\n",
        "  b2 = np.zeroes((hidden2, 1))\n",
        "\n",
        "  # Hidden2 -> Output\n",
        "  xavier_std3 = np.sqrt(2/(hidden2+output_dim))\n",
        "  w3 = np.random.normal(0, xavier_std3, (output_dim, hidden2))\n",
        "  b3 = np.zeroes((output_dim, 1))\n",
        "\n",
        "  return w1, b1, w2, b2, w3, b3"
      ],
      "metadata": {
        "id": "pvv-gH-s9yHd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Forward Propogation**\n",
        "Forward propogation is the process by which **input data is passed through a neural network to compute output predictions**.\n",
        "\n",
        "It involves performing linear transformations followed by non-linear activations at each layer.\n",
        "\n",
        "Consider a feedforward neural network with:\n",
        "\n",
        "* Input layer: $X \\in \\mathbb{R}^{n \\times d_{\\text{in}}}$\n",
        "* Hidden layers: with weights $W^{[l]}$ and biases $b^{[l]}$\n",
        "* Output layer: with weights $W^{[L]}$ and biases $b^{[L]}$\n",
        "\n",
        "**The Steps are:**\n",
        "1. Linear Transformation (Pre-activation)\n",
        "\n",
        "For the $l$-th layer:\n",
        "\n",
        "$$\n",
        "z^{[l]} = a^{[l-1]} W^{[l]} + b^{[l]}\n",
        "$$\n",
        "\n",
        "* $a^{[l-1]}$ is the activation from the previous layer (or input $X$ for the first layer).\n",
        "* $W^{[l]}$ are the layer weights, $b^{[l]}$ are biases.\n",
        "* $z^{[l]}$ is called the **pre-activation** of layer $l$.\n",
        "\n",
        "2. Activation Function:\n",
        "\n",
        "After computing the pre-activation, $$a^{[l]} = g(z^{[l]})$$\n",
        "\n",
        "The activation function introduces non-linear capabilities, allowing the network to model complex relationships\n",
        "\n",
        "3. Output Layer:\n",
        "\n",
        "For Regression Tasks, the output layer is often linear.\n",
        "$$y^{^}=z[L]$$\n",
        "\n",
        "For classification, a softmax or sigmoid activation is applied to produce probabilities.\n",
        "\n",
        "Sure! Here’s a **standard theory explanation of forward propagation** in neural networks, framed formally like you’d see in a textbook or lecture notes:\n",
        "\n",
        "___\n",
        "\n",
        "### **4. Summary of Forward Pass**\n",
        "\n",
        "1. Input $X$ → Linear transformation → Pre-activation $z^{[1]}$\n",
        "2. Apply activation → $a^{[1]}$\n",
        "3. Repeat for all hidden layers\n",
        "4. Compute output layer → $\\hat{y}$\n",
        "\n",
        "**Vectorized form** ensures efficient computation across the entire batch.\n",
        "\n",
        "\n",
        "### **Key Points**\n",
        "\n",
        "* Forward propagation is **deterministic**: given inputs and weights, outputs are uniquely determined.\n",
        "* It forms the **first step of training**: outputs are compared with true labels to compute the loss.\n",
        "* The computed activations are also used in **backpropagation** to update weights."
      ],
      "metadata": {
        "id": "6WlWKyRxDbQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forwardPass(X, w1, b1, w2, b2, w3, b3):\n",
        "  \"\"\"\n",
        "  Input -> Hidden1(Relu) -> Hidden2(Relu) --> Output(Linear)\n",
        "\n",
        "  Returns:\n",
        "    Pre-activations and activations for each layer\n",
        "  \"\"\"\n",
        "  z1 = X @ w1 + b1\n",
        "  a1 = relu(z1)\n",
        "\n",
        "  z2 = a1 @ w2 + b2\n",
        "  a2 = relu(z2)\n",
        "\n",
        "  z3 = a2 @ w3 + b3\n",
        "\n",
        "  return z1, a1, z2, a2, z3"
      ],
      "metadata": {
        "id": "xpsKa-d0DeY1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Backward Propogation**"
      ],
      "metadata": {
        "id": "W0FqodzwJiBK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OmPuUPmFMx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}